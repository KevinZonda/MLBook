# 高中数学回顾

在这一节，我们将解释为接下来学习机器所需要的基础数学概念。你可以尝试先跳过这一节，在遇到不会的数学概念，再回头看看，或许可以达到更好的效果。这一节中所讲的均为中国高中通常会介绍的内容。你无需担心如果你不是理科生而可能少学了些数学而难以前进，因为我们将只依赖如下几点：

- 求和
- 求积
- 导数
- 对数（的基础概念和运算）和 $e$
- 函数的基本定义

我会在依赖以上知识点的情况下完善机器学习所需要的数学。

## 求和

连续求和我们通常使用 $\sum$ 来表示，例如：

$$
\begin{align}
\sum_{i=1}^n i &= 1 + 2 + 3 + \ldots + n\\
&= \frac{n(n+1)}{2}
\end{align}
$$

$\sum$ 下侧的 $i=1$ 表示求和的起始位置，上侧的 $n$ 表示求和的终止位置。在这个例子中，我们将 $i$ 从 $1$ 求和到 $n$。

## 求积

连续求积我们通常使用 $\prod$ 来表示，例如：

$$
\begin{align}
\prod_{i=1}^n i &= 1 \cdot 2 \cdot 3 \cdot \ldots \cdot n\\
&= n!
\end{align}
$$

和求和运算类似， $\prod$ 下侧的 $i=1$ 表示求积的起始位置，上侧的 $n$ 表示求积的终止位置。在这个例子中，我们将 $i$ 从 $1$ 连乘到 $n$。


## 导数

导数使用 $f'(x)$表达，导数的函数值就是函数图像在这一点的切线斜率。对于一元函数，也就是微分和微元的比值，用符号语言表达就是 $f'(x)=\frac{df(x)}{dx} = \frac{d}{dx} f(x)$。二阶导数表达为 $f''(x)$或 $\frac{d}{dx}\frac{df(x)}{dx}$，也就是导数的导数。

在本书中，我们更倾向于使用 $\frac{d}{dx} f$ 的表示方法，因为其和偏导 $\frac{\partial }{\partial x} f$ 的定义更加接近。我们会在后面讨论多元函数的时候再详细讨论偏导是什么。

导数的基础公式：

导数的定义：$f'(x) = \lim_{\Delta x\to 0} \frac{f(x+\Delta x) - f(x)}{\Delta x}$

常数导数：$\frac{d}{dx} c = (c)' = 0$

幂函数导数：$\frac{d}{dx} x^n = (x^n)' = nx^{n-1}$

指数函数导数：$\frac{d}{dx} e^x = (e^x)' = e^x$

自然对数导数：$\frac{d}{dx} \ln x = (\ln x)' = \frac{1}{x}$

对数函数导数：$\frac{d}{dx} \log_a x = (\log_a x)' = \frac{1}{x\ln a}$

链式法则：$\frac{d}{dx} f(g(x)) = \frac{d f(g(x))}{d g(x)}\frac{d g(x)}{d x}$ 或 $(f(g(x)))' = f'(g(x))g'(x)$

## 对数

对数常使用 $\log$，作为标记。在机器学习中，我们可能会将 $\ln$ 与 $\log$ 等混淆，但是不用担心，我们
通常只是想方便计算。

我们知道的一些对数运算的基础公式：

$$
\begin{align}
&\log{x^y} =y\log{x} \\
&e^{\ln m} = m\\
&\log{(xy)} = \log x + \log y\\
&\log{\frac{x}{y}} = \log x - \log y\\
&\ln e = 1\\
&\log \prod f = \sum \log f
\end{align}
$$

其中最有重要的是 $\log{(xy)} = \log x + \log y$。其揭示了对数运算最重要的性质：对数可以使乘法转化为加法。

因此如果我们考虑我们需要连续乘 $k$ 次乘数 $x_i$，其中 $x_i$ 表示不同的乘子，我们可以使用 $\log$ 来简化计算：

$$
\begin{align}
\prod_{i=1}^k x_i &= x_1 \cdot x_2 \cdot \ldots \cdot x_k\\
\log \prod_{i=1}^k x_i &= \log x_1 + \log x_2 + \ldots + \log x_k\\
\log \prod_{i=1}^k x_i &= \sum_{i=1}^k \log x_i
\end{align}
$$

乘法运算对于计算机是很慢的，而加法运算是很快的。因此我们可以使用对数来简化计算。

于此同时更重要的是在计算多次概率 $p(x) \leq 1$ 的乘积时，其结果可能是一个非常非常小的数（考虑 $0.9^{100}=0.00002656139$，而计算机在存储小数时，可能会有精度丢失（也就是会不准确），而越小的数，精度可能丢失的越快。我们称这种问题为下溢出（underflow）。考虑对数可以将小数相乘转化为相加，从而避免了下溢出的问题 $\ln 0.9^{100}=100 \ln 0.9 = -10.5360515658$。

## 函数的基本定义

在初中和高中，我们对于函数的定义：函数是对空间中的元素进行映射（mapping）。

如果我们定义输入空间为 $\mathcal{X}$，输出空间为 $\mathcal{Y}$，我们可以将函数 $f$ 看作是一个对 $\mathcal{X}$ 到 $\mathcal{Y}$ 的映射，用符号我们记做 $f: \mathcal{X} \to \mathcal{Y}$。

举个例子，对于普通的一元一次线性函数 $f(x) = ax + b$，我们可以将其看作是将输入空间（即定义域， $x\in \mathbb{R}$）中的元素映射到输出空间（即值域， $f(x)\in \mathbb{R}$ ）中的元素。因此可以记作 $f: \mathbb{R} \to \mathbb{R}$。

在机器学习中，我们通常将函数看作是一个模型，即我们希望找到一个函数 $h$，使得 $h$ 能够将输入空间 $\mathcal{X}$ 中的元素正确映射到输出空间 $\mathcal{Y}$ 中的元素。
